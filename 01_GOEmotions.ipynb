{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahraniayudyaa/finnalterm-dl/blob/main/01_GOEmotions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FINE-TUNING HUGGINGFACE MODELS (GOEmotions)**"
      ],
      "metadata": {
        "id": "4BF4aWAjxCSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Setup dan Instalasi**"
      ],
      "metadata": {
        "id": "ZkOsbdcSxqx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Setup\n",
        "!pip install transformers datasets torch scikit-learn pandas numpy matplotlib seaborn\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, roc_auc_score\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from datasets import load_dataset\n",
        "import seaborn as sns\n",
        "from typing import List, Dict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "Sd4Fpoj0xV3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Load Dataset**"
      ],
      "metadata": {
        "id": "BF8qITbhxqOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Load Dataset - GoEmotions\n",
        "print(\"Loading GoEmotions dataset...\")\n",
        "dataset = load_dataset(\"google-research-datasets/go_emotions\")\n",
        "\n",
        "print(\"\\nDataset structure:\")\n",
        "print(dataset)\n",
        "print(f\"Train samples: {len(dataset['train'])}\")\n",
        "print(f\"Validation samples: {len(dataset['validation'])}\")\n",
        "print(f\"Test samples: {len(dataset['test'])}\")\n",
        "\n",
        "# Check sample\n",
        "print(\"\\nSample data:\")\n",
        "sample = dataset['train'][0]\n",
        "print(f\"Text: {sample['text']}\")\n",
        "print(f\"Labels: {sample['labels']}\")\n",
        "print(f\"Emotions: {sample['emotions']}\")\n",
        "\n",
        "# Emotion labels (28 classes)\n",
        "emotion_labels = [\n",
        "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring',\n",
        "    'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval',\n",
        "    'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief',\n",
        "    'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization',\n",
        "    'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n",
        "]\n",
        "\n",
        "print(f\"\\nTotal emotion classes: {len(emotion_labels)}\")\n",
        "\n",
        "# 3. Analyze label distribution\n",
        "def analyze_label_distribution(dataset_split, split_name):\n",
        "    print(f\"\\n{split_name} Label Analysis:\")\n",
        "\n",
        "    # Count samples with single vs multiple labels\n",
        "    single_label = 0\n",
        "    multi_label = 0\n",
        "\n",
        "    label_counts = np.zeros(len(emotion_labels))\n",
        "\n",
        "    for item in dataset_split:\n",
        "        labels = item['labels']\n",
        "        if len(labels) == 1:\n",
        "            single_label += 1\n",
        "        else:\n",
        "            multi_label += 1\n",
        "\n",
        "        for label in labels:\n",
        "            if label < len(emotion_labels):  # Ensure valid index\n",
        "                label_counts[label] += 1\n",
        "\n",
        "    total = single_label + multi_label\n",
        "    print(f\"  Single-label samples: {single_label} ({single_label/total*100:.1f}%)\")\n",
        "    print(f\"  Multi-label samples: {multi_label} ({multi_label/total*100:.1f}%)\")\n",
        "\n",
        "    # Show top emotions\n",
        "    print(f\"\\n  Top 10 emotions:\")\n",
        "    sorted_indices = np.argsort(label_counts)[::-1][:10]\n",
        "    for idx in sorted_indices:\n",
        "        print(f\"    {emotion_labels[idx]}: {int(label_counts[idx])} samples\")\n",
        "\n",
        "analyze_label_distribution(dataset['train'], 'Training')\n",
        "analyze_label_distribution(dataset['validation'], 'Validation')"
      ],
      "metadata": {
        "id": "lvHZxMbaxY-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Preprocessing Data**"
      ],
      "metadata": {
        "id": "Tklk9-h0xphP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Preprocessing - Convert to multi-hot encoding\n",
        "def convert_to_multi_hot(example):\n",
        "    # Create multi-hot vector (28 dimensions)\n",
        "    multi_hot = np.zeros(len(emotion_labels), dtype=np.float32)\n",
        "    for label in example['labels']:\n",
        "        if label < len(emotion_labels):  # Ensure valid index\n",
        "            multi_hot[label] = 1.0\n",
        "    example['labels'] = multi_hot.tolist()\n",
        "    return example\n",
        "\n",
        "print(\"\\nConverting to multi-hot encoding...\")\n",
        "dataset = dataset.map(convert_to_multi_hot)\n",
        "\n",
        "# 5. Tokenization\n",
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples['text'],\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "print(\"\\nTokenizing dataset...\")\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns(['text', 'emotions'])"
      ],
      "metadata": {
        "id": "XP07xvkixdJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Load Model dan Training**"
      ],
      "metadata": {
        "id": "Av-fv1HOxo7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Load Model for Multi-label Classification\n",
        "print(f\"\\nLoading model: {MODEL_NAME}\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=len(emotion_labels),\n",
        "    problem_type=\"multi_label_classification\"\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "# 7. Custom Metrics for Multi-label\n",
        "def compute_metrics_multi_label(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = torch.sigmoid(torch.tensor(logits)).numpy()\n",
        "\n",
        "    # Apply threshold (0.5)\n",
        "    pred_labels = (predictions > 0.5).astype(int)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(labels, pred_labels)\n",
        "    f1_micro = f1_score(labels, pred_labels, average='micro')\n",
        "    f1_macro = f1_score(labels, pred_labels, average='macro')\n",
        "\n",
        "    # Try to calculate AUC (might fail if some labels don't have positive samples)\n",
        "    try:\n",
        "        auc = roc_auc_score(labels, predictions, average='macro')\n",
        "    except:\n",
        "        auc = 0.0\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"f1_micro\": f1_micro,\n",
        "        \"f1_macro\": f1_macro,\n",
        "        \"auc_macro\": auc\n",
        "    }\n",
        "\n",
        "# 8. Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results_goemotions\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1_macro\",\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        "    report_to=\"none\",\n",
        "    save_total_limit=2\n",
        ")\n",
        "\n",
        "# 9. Data Collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# 10. Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics_multi_label\n",
        ")\n",
        "\n",
        "# 11. Train Model\n",
        "print(\"\\nTraining model for multi-label emotion classification...\")\n",
        "train_result = trainer.train()"
      ],
      "metadata": {
        "id": "2STxOVEaxgaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Evaluasi**"
      ],
      "metadata": {
        "id": "ZoKebbi_xoIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Evaluate\n",
        "print(\"\\nEvaluating model...\")\n",
        "eval_result = trainer.evaluate()\n",
        "print(f\"\\nEvaluation results:\")\n",
        "for key, value in eval_result.items():\n",
        "    print(f\"  {key}: {value:.4f}\")\n",
        "\n",
        "# 13. Test on Test Set\n",
        "print(\"\\nTesting on test set...\")\n",
        "test_results = trainer.predict(tokenized_datasets['test'])\n",
        "test_metrics = test_results.metrics\n",
        "print(f\"\\nTest set metrics:\")\n",
        "for key, value in test_metrics.items():\n",
        "    if key not in ['eval_loss', 'eval_runtime', 'eval_samples_per_second', 'eval_steps_per_second']:\n",
        "        print(f\"  {key}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "hZ-3MkcTxmma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d92cAmwlv7fs"
      },
      "outputs": [],
      "source": [
        "# 14. Save Model\n",
        "print(\"\\nSaving model...\")\n",
        "trainer.save_model(\"./saved_model_goemotions\")\n",
        "tokenizer.save_pretrained(\"./saved_model_goemotions\")\n",
        "\n",
        "# 15. Inference Function for Multi-label\n",
        "def predict_emotions(text, model, tokenizer, device, emotion_labels, threshold=0.3):\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Apply sigmoid and threshold\n",
        "    probabilities = torch.sigmoid(outputs.logits).cpu().numpy()[0]\n",
        "    predictions = (probabilities > threshold).astype(int)\n",
        "\n",
        "    # Get predicted emotions\n",
        "    predicted_indices = np.where(predictions == 1)[0]\n",
        "    predicted_emotions = [(emotion_labels[i], probabilities[i]) for i in predicted_indices]\n",
        "\n",
        "    # Sort by probability\n",
        "    predicted_emotions.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get top emotions overall\n",
        "    top5_indices = np.argsort(probabilities)[-5:][::-1]\n",
        "    top5_emotions = [(emotion_labels[i], probabilities[i]) for i in top5_indices]\n",
        "\n",
        "    return {\n",
        "        \"text\": text[:100] + \"...\" if len(text) > 100 else text,\n",
        "        \"predicted_emotions\": predicted_emotions,\n",
        "        \"probabilities\": probabilities.tolist(),\n",
        "        \"top5_emotions\": top5_emotions,\n",
        "        \"has_emotions\": len(predicted_emotions) > 0\n",
        "    }\n",
        "\n",
        "# 16. Test Inference\n",
        "test_samples = [\n",
        "    \"I'm so excited about this amazing opportunity!\",\n",
        "    \"This is absolutely terrible, I can't believe it.\",\n",
        "    \"Thank you so much for your help, I really appreciate it.\",\n",
        "    \"I'm not sure what to do, this is confusing.\",\n",
        "    \"That's hilarious, I can't stop laughing!\"\n",
        "]\n",
        "\n",
        "print(\"\\nEmotion Prediction Examples:\")\n",
        "print(\"=\" * 80)\n",
        "for text in test_samples:\n",
        "    result = predict_emotions(text, model, tokenizer, device, emotion_labels, threshold=0.3)\n",
        "    print(f\"\\nText: {result['text']}\")\n",
        "\n",
        "    if result['predicted_emotions']:\n",
        "        print(\"Predicted emotions:\")\n",
        "        for emotion, prob in result['predicted_emotions']:\n",
        "            print(f\"  - {emotion}: {prob:.2%}\")\n",
        "    else:\n",
        "        print(\"No strong emotions detected (below threshold)\")\n",
        "\n",
        "    print(\"Top 5 emotions by probability:\")\n",
        "    for emotion, prob in result['top5_emotions']:\n",
        "        print(f\"  - {emotion}: {prob:.2%}\")"
      ]
    }
  ]
}